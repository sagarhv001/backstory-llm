{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11349069,"sourceType":"datasetVersion","datasetId":7101174},{"sourceId":11359092,"sourceType":"datasetVersion","datasetId":7109224},{"sourceId":11359656,"sourceType":"datasetVersion","datasetId":7109670}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\nimport torch\n\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T09:29:57.763875Z","iopub.execute_input":"2025-04-11T09:29:57.764141Z","iopub.status.idle":"2025-04-11T09:29:59.667777Z","shell.execute_reply.started":"2025-04-11T09:29:57.764120Z","shell.execute_reply":"2025-04-11T09:29:59.667185Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"!pip install -q transformers datasets accelerate bitsandbytes","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T08:44:05.282276Z","iopub.execute_input":"2025-04-11T08:44:05.282608Z","iopub.status.idle":"2025-04-11T08:45:32.689357Z","shell.execute_reply.started":"2025-04-11T08:44:05.282585Z","shell.execute_reply":"2025-04-11T08:45:32.688640Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\n\n\ndataset = load_dataset(\"baebee/Little-Literature\")\nprint(dataset[\"train\"][0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T10:49:18.866606Z","iopub.execute_input":"2025-04-11T10:49:18.867309Z","iopub.status.idle":"2025-04-11T10:49:21.673559Z","shell.execute_reply.started":"2025-04-11T10:49:18.867281Z","shell.execute_reply":"2025-04-11T10:49:21.672818Z"}},"outputs":[{"name":"stdout","text":"{'text': 'In the heart of a bustling city, there stood a quaint bookstore, its windows adorned with the soft glow of a solitary lamp, illuminating the world within. It was a sanctuary for the lost, the dreamers, and the curious souls who sought solace in the comforting embrace of stories woven by the masters of words.'}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\n\ntokenizer = AutoTokenizer.from_pretrained(\"isarth/distill_gpt2_story_generator\")\nmodel = AutoModelForCausalLM.from_pretrained(\"isarth/distill_gpt2_story_generator\")\ntokenizer.pad_token = tokenizer.eos_token\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T10:58:35.365630Z","iopub.execute_input":"2025-04-11T10:58:35.365892Z","iopub.status.idle":"2025-04-11T10:58:35.818378Z","shell.execute_reply.started":"2025-04-11T10:58:35.365869Z","shell.execute_reply":"2025-04-11T10:58:35.817587Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\")\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T10:58:59.419373Z","iopub.execute_input":"2025-04-11T10:58:59.419644Z","iopub.status.idle":"2025-04-11T10:59:01.108796Z","shell.execute_reply.started":"2025-04-11T10:58:59.419622Z","shell.execute_reply":"2025-04-11T10:59:01.107997Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4154 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22394cdd2cae4f20a38a82675ee535e8"}},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T10:59:03.110781Z","iopub.execute_input":"2025-04-11T10:59:03.111350Z","iopub.status.idle":"2025-04-11T10:59:03.114893Z","shell.execute_reply.started":"2025-04-11T10:59:03.111325Z","shell.execute_reply":"2025-04-11T10:59:03.114132Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"print(tokenized_datasets[\"train\"][0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T10:59:06.993171Z","iopub.execute_input":"2025-04-11T10:59:06.993824Z","iopub.status.idle":"2025-04-11T10:59:06.999021Z","shell.execute_reply.started":"2025-04-11T10:59:06.993799Z","shell.execute_reply":"2025-04-11T10:59:06.998169Z"}},"outputs":[{"name":"stdout","text":"{'text': 'In the heart of a bustling city, there stood a quaint bookstore, its windows adorned with the soft glow of a solitary lamp, illuminating the world within. It was a sanctuary for the lost, the dreamers, and the curious souls who sought solace in the comforting embrace of stories woven by the masters of words.', 'input_ids': [818, 262, 2612, 286, 257, 46609, 1748, 11, 612, 6204, 257, 50127, 44346, 11, 663, 9168, 41860, 351, 262, 2705, 19634, 286, 257, 25565, 20450, 11, 46717, 262, 995, 1626, 13, 632, 373, 257, 24050, 329, 262, 2626, 11, 262, 4320, 364, 11, 290, 262, 11040, 15625, 508, 7194, 1540, 558, 287, 262, 34228, 12553, 286, 3923, 36932, 416, 262, 18159, 286, 2456, 13, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling, TrainingArguments, Trainer, TrainerCallback\n\nclass LoggingCallback(TrainerCallback):\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if logs:\n            print(f\"Step: {state.global_step} - Loss: {logs.get('loss')}\")\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    run_name=\"distilgpt2-finetune-run\",\n    logging_steps=10,        # Log every 10 steps\n    save_steps=500,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=8,  # Accumulate gradients over 8 steps (2*8 = 16 samples per update)\n    num_train_epochs=3,      # Train for 3 epochs\n    weight_decay=0.01,\n    save_total_limit=2,\n    report_to=[]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T10:59:16.893543Z","iopub.execute_input":"2025-04-11T10:59:16.894006Z","iopub.status.idle":"2025-04-11T10:59:16.926326Z","shell.execute_reply.started":"2025-04-11T10:59:16.893982Z","shell.execute_reply":"2025-04-11T10:59:16.925778Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    data_collator=data_collator,\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T10:59:19.978141Z","iopub.execute_input":"2025-04-11T10:59:19.978393Z","iopub.status.idle":"2025-04-11T10:59:20.129020Z","shell.execute_reply.started":"2025-04-11T10:59:19.978373Z","shell.execute_reply":"2025-04-11T10:59:20.128479Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"trainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T10:59:22.407267Z","iopub.execute_input":"2025-04-11T10:59:22.407498Z","iopub.status.idle":"2025-04-11T11:20:45.902346Z","shell.execute_reply.started":"2025-04-11T10:59:22.407482Z","shell.execute_reply":"2025-04-11T11:20:45.901761Z"}},"outputs":[{"name":"stderr","text":"`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='387' max='387' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [387/387 21:18, Epoch 2/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.214100</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.068600</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.237700</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.726600</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.856700</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.945500</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.600200</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.803800</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.571000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.556900</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>1.596700</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.621400</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>1.733000</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.599400</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.645300</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>1.206200</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>1.352500</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.187700</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>1.260900</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.080700</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>1.376600</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>1.083700</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>1.294500</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>1.232700</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.520800</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>1.591900</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>1.392500</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>1.450200</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>1.308700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.160300</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>1.246300</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>1.280000</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>1.233300</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>1.359000</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.246300</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>1.186300</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>1.211800</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>1.237300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=387, training_loss=1.4786362216762179, metrics={'train_runtime': 1283.1294, 'train_samples_per_second': 9.712, 'train_steps_per_second': 0.302, 'total_flos': 3240079707340800.0, 'train_loss': 1.4786362216762179, 'epoch': 2.9932627526467757})"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import pipeline\n\ntext_gen = pipeline(\"text-generation\", model=trainer.model, tokenizer=tokenizer)\n\nprompt = '''f\"Write a vivid, emotionally grounded backstory for the following character. Avoid meta-commentary, real-world references, or speculation.\\n Prompt: {\"name\": \"Themis\", \"description\": \"Birth and early days: She was born from Gaia along with her younger sister Mnemosyne. She became the embodiment of divine order, law, and custom, giving the Titans a purpose to be part of the world. After Cronos overthrew and slayed his father Ouranos, she and several titans became his close allies. She pledged herself to him, but disagreed with his cruel methods. Powers & Abilities: Immortality — she is immortal and only a sufficiently powerful weapon or being can kill her. Divination — she can foresee the future and see the past of every being. Omniscience — she can see the past, present, and future of every creature.\"}\nBackstory: '''\n\noutput = text_gen(prompt, max_new_tokens=200, repetition_penalty=1.2, do_sample=True, temperature=0.4)\n\nprint(output[0]['generated_text'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T11:22:58.994422Z","iopub.execute_input":"2025-04-11T11:22:58.994749Z","iopub.status.idle":"2025-04-11T11:23:00.259682Z","shell.execute_reply.started":"2025-04-11T11:22:58.994723Z","shell.execute_reply":"2025-04-11T11:23:00.259035Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"f\"Write a vivid, emotionally grounded backstory for the following character. Avoid meta-commentary, real-world references, or speculation.\n Prompt: {\"name\": \"Themis\", \"description\": \"Birth and early days: She was born from Gaia along with her younger sister Mnemosyne. She became the embodiment of divine order, law, and custom, giving the Titans a purpose to be part of the world. After Cronos overthrew and slayed his father Ouranos, she and several titans became his close allies. She pledged herself to him, but disagreed with his cruel methods. Powers & Abilities: Immortality — she is immortal and only a sufficiently powerful weapon or being can kill her. Divination — she can foresee the future and see the past of every being. Omniscience — she can see the past, present, and future of every creature.\"}\nBackstory:  The story begins in this small town named after its ancient owner - an old man who had been watching through trees as if performing magic on their own deathbeds before he died by lightning's power alone upon reaching higher ebb than ever else would've seen... Here lies where there are tales that might inspire you all time ago!In our darkest hour we find solace at nightfallen peaks above dawn; amidst those gentle shadows whispers creaked whisperings beneath midnight stars like thunderbirds' songworsing wings gleamed against dusk skylike mist over usadows hovered belowdawn skies waltzed into darkness until morning lighted up skyscrapers glittered overhead..And yet it never touched me once more\".As I gazed closer my eye felt something peculiar about these stories? And then suddenly did they touch each other again?\"I feel torn between memories woven deep within them anew...\"Oh yes,\" said another breathless sigh undercurrentity still held hold swayingly towardsthe ground floor beyond\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"trainer.save_model(\"./backstory-model\")\ntokenizer.save_pretrained(\"./backstory-model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T11:23:12.628204Z","iopub.execute_input":"2025-04-11T11:23:12.628737Z","iopub.status.idle":"2025-04-11T11:23:13.881402Z","shell.execute_reply.started":"2025-04-11T11:23:12.628716Z","shell.execute_reply":"2025-04-11T11:23:13.880785Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"('./backstory-model/tokenizer_config.json',\n './backstory-model/special_tokens_map.json',\n './backstory-model/vocab.json',\n './backstory-model/merges.txt',\n './backstory-model/added_tokens.json',\n './backstory-model/tokenizer.json')"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"backstory_model\", 'zip', \"/kaggle/working/backstory-model\")  # (\"output_name\", format, \"folder_path\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T11:23:16.995496Z","iopub.execute_input":"2025-04-11T11:23:16.995758Z","iopub.status.idle":"2025-04-11T11:23:33.543029Z","shell.execute_reply.started":"2025-04-11T11:23:16.995738Z","shell.execute_reply":"2025-04-11T11:23:33.542196Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/backstory_model.zip'"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('backstory_model.zip')  # click this link in notebook to download\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T11:23:41.278337Z","iopub.execute_input":"2025-04-11T11:23:41.278647Z","iopub.status.idle":"2025-04-11T11:23:41.283724Z","shell.execute_reply.started":"2025-04-11T11:23:41.278621Z","shell.execute_reply":"2025-04-11T11:23:41.283083Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/backstory_model.zip","text/html":"<a href='backstory_model.zip' target='_blank'>backstory_model.zip</a><br>"},"metadata":{}}],"execution_count":45}]}